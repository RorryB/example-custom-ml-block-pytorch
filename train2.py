#!/usr/bin/env python3
# Patched train.py — cleaned imports and adds:
#  - ONNX export with batch size 1
#  - attempt to run onnx2tf conversion (python -m onnx2tf -i ...)
#  - create a compat shim SavedModel at out/onnx2tf-out exposing `.layers`
#
# This file is based on the original in the repository and includes the compat shim
# so Edge Impulse postprocessing that expects a TF SavedModel with `.layers` will not fail.

import os
import sys
import json
import time
import argparse
import traceback
import subprocess as _subprocess
import shutil
import glob

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader

# PerforatedAI helpers (kept as in original)
from perforatedai import globals_perforatedai as GPA
from perforatedai import utils_perforatedai as UPA

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# -------------------------
# Arguments
# -------------------------
parser = argparse.ArgumentParser(description='Running custom PyTorch models in Edge Impulse')

# Data / run args
parser.add_argument('--data-directory', type=str, default='data')
parser.add_argument('--out-directory', type=str, default='out')

# Baseline arguments
parser.add_argument('--epochs', type=int, default=100)
parser.add_argument('--batch_size', type=int, default=32)
parser.add_argument('--learning-rate', type=float, default=0.001)
parser.add_argument('--seed', type=int, default=0)
parser.add_argument('--dropout', type=float, default=0.1)
parser.add_argument('--num_conv', type=int, default=3, choices=[1,2,3])
parser.add_argument('--num_linear', type=int, default=2, choices=[1,2])
parser.add_argument('--network_width', type=float, default=2, help="Width multiplier for channels")
parser.add_argument('--noise_std', type=float, default=0, help="Gaussian noise stddev during training")
parser.add_argument('--channel_growth_mode', type=int, default=5, choices=[0,1,2,3,4,5])
parser.add_argument('--dendritic-optimization', type=str, required=False, default="false")
parser.add_argument('--switch_speed', type=str, default='slow', help="speed to switch", choices=['slow', 'medium', 'fast'])
parser.add_argument('--max_dendrites', type=int, default=3)
parser.add_argument('--improvement_threshold', type=str, default='medium', choices=['high', 'medium', 'low'])
parser.add_argument('--dendrite_weight_initialization_multiplier', type=float, default=0.01)
parser.add_argument('--dendrite_forward_function', type=str, default='tanh', choices=['relu','sigmoid','tanh'])
parser.add_argument('--dendrite-conversion', type=str, default='All Layers', choices=['Linear Only','All Layers'])
parser.add_argument('--improved-dendritic-optimization', type=str, required=False, default="false")
parser.add_argument('--perforated-ai-token', type=str, required=False, default="")

args, unknown = parser.parse_known_args()

os.environ["PAIEMAIL"] = "user@edgeimpulse.com"
os.environ["PAITOKEN"] = args.perforated_ai_token

os.makedirs(args.out_directory, exist_ok=True)

def str2bool(value: str) -> bool:
    return str(value).lower() in ("1", "true", "t", "yes", "y")

# -------------------------
# Load data
# -------------------------
X_train = np.load(os.path.join(args.data_directory, 'X_split_train.npy'), mmap_mode='r')
Y_train = np.load(os.path.join(args.data_directory, 'Y_split_train.npy'))
X_test = np.load(os.path.join(args.data_directory, 'X_split_test.npy'), mmap_mode='r')
Y_test = np.load(os.path.join(args.data_directory, 'Y_split_test.npy'))

# Split test set in half for test and validation (same logic as original)
split_idx = len(X_test) // 2
X_val = X_test[:split_idx]
Y_val = Y_test[:split_idx]
X_test = X_test[split_idx:]
Y_test = Y_test[split_idx:]

# Convert to tensors on device
X_train = torch.FloatTensor(X_train).to(device)
Y_train = torch.FloatTensor(Y_train).to(device)
X_val = torch.FloatTensor(X_val).to(device)
Y_val = torch.FloatTensor(Y_val).to(device)
X_test = torch.FloatTensor(X_test).to(device)
Y_test = torch.FloatTensor(Y_test).to(device)

train_dataset = TensorDataset(X_train, Y_train)
val_dataset = TensorDataset(X_val, Y_val)
test_dataset = TensorDataset(X_test, Y_test)

if args.seed >= 0:
    torch.manual_seed(args.seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=False)
val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False)
test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False)

# -------------------------
# Model definition (kept mostly identical)
# -------------------------
class AudioClassifier(nn.Module):
    def __init__(self, input_length, classes, num_conv=2, num_linear=1, width=1.0, linear_dropout=0.5, noise_std = 0.2, growth_mode=0):
        super(AudioClassifier, self).__init__()
        assert 0 <= num_conv <= 4
        assert 1 <= num_linear <= 2
        assert 0.0625 <= width <= 8.0
        assert 0.0 <= linear_dropout <= 1.0

        self.input_length = input_length
        self.classes = classes
        self.num_conv = num_conv
        self.num_linear = num_linear
        self.width = width
        self.linear_dropout = linear_dropout
        self.noise_std = noise_std

        self.channels = 1
        self.columns = 13
        self.rows = int(input_length / (self.columns * self.channels))

        if(growth_mode == 0):
            base_channels = [8, 16, 32, 64]
        elif growth_mode == 1:
            base_channels = [8, 16, 24, 32]
        elif growth_mode == 2:
            base_channels = [8, 16, 16, 32]
        elif growth_mode == 3:
            base_channels = [8, 16, 16, 16]
        elif growth_mode == 4:
            base_channels = [8, 8, 8, 8]
        elif growth_mode == 5:
            base_channels = [8, 8, 8, 16]
        self.channel_sizes = [max(1, int(ch * width)) for ch in base_channels]

        self.conv_blocks = nn.ModuleList()
        self._constrained_conv_layers = []
        self.conv_hooks = []

        if num_conv > 0:
            in_channels = self.channels
            for i in range(num_conv):
                out_channels = self.channel_sizes[i]
                conv_block = nn.Sequential(
                    nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding='same'),
                    nn.ReLU(),
                    nn.MaxPool2d(kernel_size=2, stride=2),
                    nn.Dropout(0.25)
                )
                self.conv_blocks.append(conv_block)
                conv_layer = conv_block[0]
                self._constrained_conv_layers.append(conv_layer)
                in_channels = out_channels

        if num_conv > 0:
            final_rows = self.rows // (2 ** num_conv)
            final_cols = self.columns // (2 ** num_conv)
            flattened_size = self.channel_sizes[num_conv - 1] * final_rows * final_cols
        else:
            flattened_size = input_length

        self.linear_layers = nn.ModuleList()
        linear_sizes = self._calculate_linear_sizes(flattened_size, classes, num_linear)

        for i in range(num_linear - 1):
            self.linear_layers.append(nn.Sequential(
                nn.Dropout(linear_dropout),
                nn.Linear(linear_sizes[i], linear_sizes[i + 1]),
                nn.ReLU()
            ))

        self.linear_layers.append(nn.Sequential(
            nn.Dropout(linear_dropout),
            nn.Linear(linear_sizes[-2], linear_sizes[-1])
        ))

    def _calculate_linear_sizes(self, input_size, output_size, num_layers):
        if num_layers == 1:
            return [input_size, output_size]
        sizes = [input_size]
        log_start = torch.log(torch.tensor(float(input_size)))
        log_end = torch.log(torch.tensor(float(output_size)))
        for i in range(1, num_layers):
            ratio = i / num_layers
            log_size = log_start + (log_end - log_start) * ratio
            size = max(output_size, int(torch.exp(log_size).item()))
            sizes.append(size)
        sizes.append(output_size)
        return sizes

    def _max_norm_constraint_tensor(self, weight: torch.Tensor, max_value=1.0) -> torch.Tensor:
        norm = weight.norm(2, dim=(1, 2, 3), keepdim=True)
        desired = torch.clamp(norm, max=max_value)
        scale = (desired / (norm + 1e-8))
        return weight * scale

    def enforce_max_norm(self, max_value=1.0):
        for module in self._constrained_conv_layers:
            if hasattr(module, 'weight'):
                with torch.no_grad():
                    norm = module.weight.norm(2, dim=(1, 2, 3), keepdim=True)
                    desired = torch.clamp(norm, max=max_value)
                    module.weight *= (desired / (norm + 1e-8))

    def forward(self, x):
        if self.training:
            noise = torch.randn_like(x) * self.noise_std
            x = x + noise
        if self.num_conv > 0:
            x = x.view(-1, self.channels, self.rows, self.columns)
            for conv_block in self.conv_blocks:
                x = conv_block(x)
            x = x.view(x.size(0), -1)
        for linear_layer in self.linear_layers:
            x = linear_layer(x)
        return x

# -------------------------
# Main training loop (kept from original)
# -------------------------
def main(config):
    # config is the argparse.Namespace (args)
    # PerforatedAI config
    if args.improvement_threshold == 'high':
        thresh = [0.01, 0.001, 0.0001, 0]
    elif args.improvement_threshold == 'medium':
        thresh = [0.001, 0.0001, 0]
    else:
        thresh = [0]
    GPA.pc.set_improvement_threshold(thresh)
    GPA.pc.set_candidate_weight_initialization_multiplier(args.dendrite_weight_initialization_multiplier)
    if args.dendrite_forward_function == 'sigmoid':
        pai_forward_function = torch.sigmoid
    elif args.dendrite_forward_function == 'relu':
        pai_forward_function = torch.relu
    else:
        pai_forward_function = torch.tanh
    GPA.pc.set_pai_forward_function(pai_forward_function)

    if args.dendrite_conversion == 'All Layers':
        GPA.pc.set_modules_to_convert([nn.Conv2d, nn.Linear])
        GPA.pc.set_modules_to_track([])
    else:
        GPA.pc.set_modules_to_convert([nn.Linear])
        GPA.pc.set_modules_to_track([nn.Conv2d])

    GPA.pc.set_max_dendrites(args.max_dendrites if str2bool(args.dendritic_optimization) else 0)
    GPA.pc.set_perforated_backpropagation(str2bool(args.improved_dendritic_optimization))
    GPA.pc.set_dendrite_update_mode(True)
    GPA.pc.set_initial_correlation_batches(40)

    # Instantiate model
    input_length = 624
    classes = 3
    model = AudioClassifier(input_length, classes,
                            num_conv=args.num_conv,
                            num_linear=args.num_linear,
                            width=args.network_width,
                            linear_dropout=args.dropout,
                            noise_std=args.noise_std,
                            growth_mode=args.channel_growth_mode).to(device)

    GPA.pc.set_testing_dendrite_capacity(False)

    if args.switch_speed == 'fast':
        GPA.pc.set_n_epochs_to_switch(10)
    elif args.switch_speed == 'medium':
        GPA.pc.set_n_epochs_to_switch(25)
    else:
        GPA.pc.set_n_epochs_to_switch(100)

    GPA.pc.set_verbose(False)
    GPA.pc.set_silent(True)

    model = UPA.initialize_pai(model)
    print(model)

    GPA.pai_tracker.set_optimizer(torch.optim.Adam)
    GPA.pai_tracker.set_scheduler(torch.optim.lr_scheduler.ReduceLROnPlateau)
    optimArgs = {'params':model.parameters(), 'lr':args.learning_rate, 'betas':(0.9, 0.999)}
    schedArgs = {'mode':'max', 'patience': 5}
    optimizer, PAIscheduler = GPA.pai_tracker.setup_optimizer(model, optimArgs, schedArgs)

    criterion = nn.CrossEntropyLoss()

    def train_epoch(model, loader, criterion, optimizer, device):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        for inputs, labels in loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            if labels.dim() > 1 and labels.size(1) > 1:
                labels = torch.argmax(labels, dim=1)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            if hasattr(model, 'enforce_max_norm'):
                model.enforce_max_norm(max_value=1.0)
            running_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
        return running_loss / total, correct / total

    def test(model, loader, criterion, device):
        model.eval()
        running_loss = 0.0
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                if labels.dim() > 1 and labels.size(1) > 1:
                    labels = torch.argmax(labels, dim=1)
                loss = criterion(outputs, labels)
                running_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        return running_loss / total, correct / total

    # Training loop
    first_test_loss = 0
    first_test_acc = 0
    first_val_loss = 0
    first_val_acc = 0
    first_param_count = UPA.count_params(model)

    epoch = -1
    while True:
        epoch += 1
        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)
        val_loss, val_acc = test(model, val_loader, criterion, device)
        test_loss, test_acc = test(model, test_loader, criterion, device)

        GPA.pai_tracker.add_extra_score(train_acc, 'Train')
        GPA.pai_tracker.add_extra_score(test_acc, 'Test')
        model, restructured, training_complete = GPA.pai_tracker.add_validation_score(val_acc, model)
        model.to(device)
        if training_complete:
            break
        elif restructured:
            if first_test_loss == 0:
                first_test_loss = test_loss
                first_test_acc = test_acc
                first_val_loss = val_loss
                first_val_acc = val_acc
            print('Restructured dendritic architecture')
            optimArgs = {'params':model.parameters(), 'lr':args.learning_rate, 'betas':(0.9, 0.999)}
            schedArgs = {'mode':'max', 'patience': 5}
            optimizer, PAIscheduler = GPA.pai_tracker.setup_optimizer(model, optimArgs, schedArgs)

        print(f'Epoch {epoch+1} Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} | Dendrite Count and Mode: {GPA.pai_tracker.member_vars["num_dendrites_added"]} - {GPA.pai_tracker.member_vars["mode"]}')

    test_loss, test_acc = test(model, test_loader, criterion, device)

    if str2bool(args.dendritic_optimization):
        print(f'First architecture: Val Acc: {first_val_acc:.4f}, Test Acc: {first_test_acc:.4f}, params: {first_param_count}')
        print(f'Final architecture: Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}, params: {UPA.count_params(model)} Dendrite Count: {GPA.pai_tracker.member_vars["num_dendrites_added"]}')
        print('Reduction in misclassifications because of dendrites')
        print(f'Validation: {(100.0*((val_acc-first_val_acc)/(1-first_val_acc))):.2f}%')
        print(f'Test: {(100.0*((test_acc-first_test_acc)/(1-first_test_acc))):.2f}%')
    else:
        print(f'Final architecture: Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}, params: {UPA.count_params(model)} Dendrite Count: {GPA.pai_tracker.member_vars["num_dendrites_added"]}')

    # -------------------------
    # Save/export for Edge Impulse
    # -------------------------
    from perforatedbp import network_pbp as PBN
    model = AudioClassifier(input_length, classes, num_conv=args.num_conv, num_linear=args.num_linear, width=args.network_width, linear_dropout=args.dropout, noise_std=args.noise_std, growth_mode=args.channel_growth_mode).to(device)

    if not str2bool(args.improved_dendritic_optimization):
        from perforatedbp import utils_pbp as PBU
        model = UPA.initialize_pai(model)
        model = UPA.load_system(model, 'PAI', 'best_model', True)
        PBU.pb_save_net(model,'PAI','best_model')
        model = AudioClassifier(input_length, classes, num_conv=args.num_conv, num_linear=args.num_linear, width=args.network_width, linear_dropout=args.dropout, noise_std=args.noise_std, growth_mode=args.channel_growth_mode).to(device)

    model = PBN.load_pai_model(model, 'PAI/best_model_pai.pt')
    for i, block in enumerate(model.conv_blocks):
        for conv in block[0].layer_array:
            if conv.padding == 'same':
                if isinstance(conv.kernel_size, tuple):
                    padding = tuple((k - 1) // 2 for k in conv.kernel_size)
                else:
                    padding = (conv.kernel_size - 1) // 2
                conv.padding = padding

    # remove any forward hooks commented out in original
    # export ONNX with batch size 1 (important)
    onnx_path = os.path.join(args.out_directory, 'model.onnx')
    torch.onnx.export(model.cpu(),
                      torch.randn((1, input_length)),
                      onnx_path,
                      export_params=True,
                      opset_version=10,
                      do_constant_folding=True,
                      input_names=['input'],
                      output_names=['output'])
    print("Exported ONNX to", onnx_path)

    # Attempt to run onnx2tf (so EI won't need to re-run it)
    saved_model_dir = os.path.join(args.out_directory, 'onnx2tf-out')
    try:
        cmd = [sys.executable, "-m", "onnx2tf", "-i", onnx_path, "-o", saved_model_dir]
        print("[train] Running onnx2tf:", " ".join(cmd))
        proc = _subprocess.run(cmd, stdout=_subprocess.PIPE, stderr=_subprocess.PIPE, text=True)
        print("[train] onnx2tf stdout:\n", proc.stdout)
        print("[train] onnx2tf stderr:\n", proc.stderr)
        if proc.returncode == 0 and os.path.isdir(saved_model_dir):
            print("[train] onnx2tf conversion succeeded, SavedModel at:", saved_model_dir)
        else:
            print("[train] onnx2tf conversion returned code", proc.returncode, "- continuing to create compat shim (EI may convert later).")
    except Exception:
        print("[train] Failed to invoke onnx2tf CLI; continuing and creating compat shim.")
        traceback.print_exc()

    # Create compat shim SavedModel at out/onnx2tf-out that exposes .layers (used by EI embeddings)
    try:
        # Import TF lazily so environments without TF can still run training portion
        import tensorflow as tf
    except Exception:
        tf = None
        print("[train] TensorFlow not available in this environment; cannot create compat shim. If running inside EI, ensure TF is installed.")

    if tf is not None:
        try:
            print("[compat-shim] Target SavedModel dir:", saved_model_dir)
            loaded = None
            if os.path.isdir(saved_model_dir):
                try:
                    loaded = tf.saved_model.load(saved_model_dir)
                    print("[compat-shim] Loaded existing SavedModel from", saved_model_dir)
                except Exception:
                    print("[compat-shim] Failed to load existing SavedModel (will still create shim):")
                    traceback.print_exc()
            else:
                print("[compat-shim] No existing SavedModel at", saved_model_dir, "- creating shim fallback.")

            # Try to find a backend callable
            backend_fn = None
            if loaded is not None:
                try:
                    sigs = getattr(loaded, 'signatures', None)
                    if sigs and 'serving_default' in sigs:
                        backend_fn = sigs['serving_default']
                        print("[compat-shim] Using signatures['serving_default'] as backend function.")
                except Exception:
                    pass

            if backend_fn is None and loaded is not None:
                try:
                    candidate = tf.function(lambda x: loaded(x))
                    il = int(input_length) if 'input_length' in locals() else 624
                    _ = candidate.get_concrete_function(tf.TensorSpec([1, il], tf.float32))
                    backend_fn = candidate
                    print("[compat-shim] Using tf.function(lambda x: loaded(x)) as backend.")
                except Exception:
                    pass

            if backend_fn is None and loaded is not None:
                for name in dir(loaded):
                    if name.startswith('_'):
                        continue
                    attr = getattr(loaded, name)
                    if callable(attr):
                        backend_fn = attr
                        print(f"[compat-shim] Using callable attribute '{name}' from loaded SavedModel as backend.")
                        break

            if backend_fn is None:
                print("[compat-shim] No backend callable found. Creating fallback backend that returns zeros.")
                try:
                    out_dim = int(classes) if 'classes' in locals() else 3
                except Exception:
                    out_dim = 3

                @tf.function(input_signature=[tf.TensorSpec([1, int(input_length) if 'input_length' in locals() else 624], tf.float32)])
                def backend_fn(x):
                    return tf.zeros((1, out_dim), dtype=tf.float32)

            # Determine output dim
            out_dim = None
            try:
                test_inp = tf.constant(np.zeros((1, int(input_length) if 'input_length' in locals() else 624), dtype=np.float32))
                try:
                    test_out = backend_fn(test_inp)
                except Exception:
                    try:
                        test_out = list(backend_fn(test_inp).values())[0]
                    except Exception:
                        test_out = None
                if test_out is not None:
                    to = tf.convert_to_tensor(test_out)
                    out_shape = to.shape
                    if len(out_shape) >= 2:
                        out_dim = int(out_shape[-1])
                    else:
                        out_dim = int(out_shape[0])
                    print("[compat-shim] Detected output dim:", out_dim)
            except Exception:
                print("[compat-shim] Could not infer output dim; will use fallback if needed.")
                traceback.print_exc()

            if out_dim is None:
                try:
                    out_dim = int(classes) if 'classes' in locals() else 3
                except Exception:
                    out_dim = 3
                print("[compat-shim] Using fallback output dim:", out_dim)

            # Define LayerContainer and compat module
            class LayerContainer(tf.Module):
                def __init__(self):
                    super().__init__()
                    self.layer_0 = tf.keras.layers.Layer(name='compat_dummy_layer')
                def __len__(self):
                    return 1
                def __getitem__(self, idx):
                    if idx == 0:
                        return getattr(self, 'layer_0')
                    raise IndexError

            class CompatModule(tf.Module):
                def __init__(self, backend_callable, output_dim):
                    super().__init__()
                    self.layers = LayerContainer()
                    self._backend = backend_callable
                    self._output_dim = output_dim

                @tf.function(input_signature=[tf.TensorSpec([1, int(input_length) if 'input_length' in locals() else 624], tf.float32)])
                def serving_default(self, x):
                    try:
                        res = self._backend(x)
                    except Exception:
                        res = self._backend(x)
                    if isinstance(res, dict):
                        res = list(res.values())[0]
                    res_t = tf.convert_to_tensor(res, dtype=tf.float32)
                    try:
                        res_t = tf.reshape(res_t, [1, self._output_dim])
                    except Exception:
                        pass
                    return res_t

            compat = CompatModule(backend_fn, out_dim)

            # Overwrite existing SavedModel dir
            try:
                if os.path.isdir(saved_model_dir):
                    shutil.rmtree(saved_model_dir)
                    print("[compat-shim] Removed existing SavedModel dir to be replaced with compat shim.")
            except Exception:
                print("[compat-shim] Failed to remove existing SavedModel dir; continuing.")

            try:
                tf.saved_model.save(compat, saved_model_dir, signatures={'serving_default': compat.serving_default})
                print("[compat-shim] Saved compat shim at:", saved_model_dir)
                print("[compat-shim] Now tf.saved_model.load(saved_model_dir) will return an object with .layers.")
            except Exception:
                print("[compat-shim] Failed to save compat shim:")
                traceback.print_exc()

        except Exception:
            print("[compat-shim] Unexpected error during shim creation:")
            traceback.print_exc()
    else:
        print("[train] TensorFlow not present — compat shim not created.")

if __name__ == "__main__":
    main(args)
